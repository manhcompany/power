etl = {
  datasetA = {
    input = {
      path = "/Users/manhtran/Documents/code/power/spark/src/test/resources/input/input.csv"
      format = "csv"
      options = [
        {key = "header", value = true}
      ]
    }
    actions = [
      {
        operator = SELECT
        exprs = ["id as ID", "age as AGE", "act_name as act_name"]
      }
      {
        operator = DROPNULL
        columns = [
          """ID"""
        ]
      }
      {
        operator = FILTER
        exprs = [
          """ID = 1 or ID = 2"""
        ]
      }
      {
        operator = REPARTITION
        partitions = 1
      }
      {
        operator = AS_TEMP_TABLE
        table-name = """ABC"""
      }
    ]
  }

  films = {
    input = {
      path = "/Users/manhtran/Documents/code/power/spark/src/test/resources/input/films.csv"
      format = "csv"
      options = [
        {key = "header", value = true}
      ]
    }
    actions = [
      {
        operator = AS_TEMP_TABLE
        table-name = """films"""
      }
      {
        operator = SELECT
        exprs = ["""act_id as id""", """name"""]
      }
    ]
  }

  join_2 = {
    input = {
      load = "datasetA"
    }
    actions = [
      {
        operator = JOIN
        exprs = ["id"]
        join-type = "inner"
        options = [
          { key = "OTHER_DATASETS", value = "films" }
        ]
      }
    ]
    output = {
      path = "/Users/manhtran/Documents/code/power/spark/src/test/resources/output/join_2"
      format = "csv"
      mode = "overwrite"
      options = [
        {key = "header", value = true}
      ]
    }
  }

  join = {
    actions = [
      {
        operator = SQL
        sql = "select films.name as film_name, ABC.act_name as act_name from films inner join ABC on films.act_id = ABC.ID"
        options = [
          {key = "OTHER_DATASETS", value = "datasetA"}
          {key = "OTHER_DATASETS", value = "films"}
        ]
      }
      {
        operator = RENAME
        columns = [
          """ film_name >> FILM_NAME_XXX """
        ]
      }
      {
        operator = DEDUPLICATE
        colums = [
          """ FILM_NAME_XXX """
        ]
      }
      {
        operator = REPARTITION
        partitions = 1
      }
    ]
    output = {
      path = "/Users/manhtran/Documents/code/power/spark/src/test/resources/output/join"
      format = "csv"
      mode = "overwrite"
      options = [
        {key = "header", value = true}
      ]
    }
  }

  max = {
    actions = [
      {
        operator = SQL
        sql = """select max(ID) as MAX from ABC"""
        options = [
          {key = "OTHER_DATASETS", value = "datasetA"}
        ]
      }
    ]
  }

  us = {
    input = {
      path = "/Users/manhtran/Documents/code/power/spark/src/test/resources/input/us.csv"
      format = "csv"
      options = [
        {key = "header", value = true}
      ]
    }
  }
}