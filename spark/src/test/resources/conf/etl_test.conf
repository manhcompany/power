etl = {
  datasetA = {
    input = {
      path = "/Users/manhtran/Documents/code/power/spark/src/test/resources/input/input.csv"
      format = "csv"
      options = [
        { key = "header", value = true }
      ]
    }
    actions = [
      {
        operator = SELECT
        exprs = ["id as ID" , "age as AGE", "name as NAME" ]
      }
      {
        operator = DROPNULL
        columns = [
          """ID"""
        ]
      }
      {
        operator = FILTER
        exprs = [
          """ID = 1 or ID = 2"""
        ]
      }
      {
        operator = REPARTITION
        partitions = 1
      }
      {
        operator = AS_TEMP_TABLE
        table-name = """ABC"""
      }
    ]
  }

  films = {
    input = {
      path = "/Users/manhtran/Documents/code/power/spark/src/test/resources/input/films.csv"
      format = "csv"
      options = [
        { key = "header", value = true }
      ]
    }
    actions = [
      {
        operator = AS_TEMP_TABLE
        table-name = """films"""
      }
    ]
  }

  join = {
    actions = [
      {
        operator = SQL
        sql = "select films.name as film_name, ABC.name as act_name from films inner join ABC on films.act_id = ABC.ID"
        options = [
          { key = "OTHER_DATASETS", value = "datasetA" }
          { key = "OTHER_DATASETS", value = "films" }
        ]
      }
      {
        operator = RENAME
        columns = [
          """ film_name >> FILM_NAME_XXX """
        ]
      }
      {
        operator = DEDUPLICATE
        colums = [
          """ FILM_NAME_XXX """
        ]
      }
      {
        operator = REPARTITION
        partitions = 1
      }
    ]
    output = {
      path = "/Users/manhtran/Documents/code/power/spark/src/test/resources/output/join"
      format = "csv"
      mode = "overwrite"
      options = [
        { key = "header", value = true }
      ]
    }
  }
}